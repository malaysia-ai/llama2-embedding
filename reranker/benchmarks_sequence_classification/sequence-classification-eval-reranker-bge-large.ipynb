{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import flash_attn\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, classification_report, \\\n",
    "                            roc_auc_score, confusion_matrix\n",
    "\n",
    "model_used = 'bge-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load reranker model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-reranker-large\")\n",
    "reranker_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"BAAI/bge-reranker-large\",\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    use_cache = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push model to the GPU!\n",
    "_ = reranker_model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 20 14:35:46 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA A100 80GB PCIe          On  | 00000001:00:00.0 Off |                    0 |\r\n",
      "| N/A   33C    P0              64W / 300W |   2578MiB / 81920MiB |      0%      Default |\r\n",
      "|                                         |                      |             Disabled |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_datasets/test-reformatted-common-crawl-qa.jsonl',\n",
       " 'test_datasets/test-reformatted-facebook.jsonl',\n",
       " 'test_datasets/test-reformatted-hansard-qa.jsonl',\n",
       " 'test_datasets/test-reformatted-iium-confession.jsonl',\n",
       " 'test_datasets/test-reformatted-mining-b-cari-com-my.jsonl',\n",
       " 'test_datasets/test-reformatted-mining-summarization.jsonl',\n",
       " 'test_datasets/test-reformatted-news.jsonl',\n",
       " 'test_datasets/test-reformatted-twitter.jsonl',\n",
       " 'test_datasets/test-reformatted-wikipedia-qa.jsonl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list down available files\n",
    "files = sorted(glob.glob('test_datasets/test-reformatted-*.jsonl'))\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Common Crawl QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (20949, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagaimana cara penghantaran dan kos penghantar...</td>\n",
       "      <td>Ladam merupakan barang buatan yang lazimnya di...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apakah jenama bateri kereta yang disediakan ol...</td>\n",
       "      <td>Komik adalah sejenis seni visual yang menggabu...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apakah kawasan liputan untuk servis hantar bat...</td>\n",
       "      <td>untuk memecat Lawton, meninggalkan sekali lagi...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Bagaimana cara penghantaran dan kos penghantar...   \n",
       "1  Apakah jenama bateri kereta yang disediakan ol...   \n",
       "2  Apakah kawasan liputan untuk servis hantar bat...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Ladam merupakan barang buatan yang lazimnya di...      0  test   \n",
       "1  Komik adalah sejenis seni visual yang menggabu...      0  test   \n",
       "2  untuk memecat Lawton, meninggalkan sekali lagi...      0  test   \n",
       "\n",
       "    dataset_source  \n",
       "0  common-crawl-qa  \n",
       "1  common-crawl-qa  \n",
       "2  common-crawl-qa  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-common-crawl-qa.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c662eb4edb48461f817660db1837db83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2095 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t, max_length=512, truncation=True)\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        output = reranker_model(**padded).logits.view(-1, ).cpu().detach().float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.709771349467755\n",
      "ROC-AUC: 0.7097575266496925\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.63285   0.99933   0.77495     10475\n",
      "     class 1    0.99841   0.42018   0.59145     10474\n",
      "\n",
      "    accuracy                        0.70977     20949\n",
      "   macro avg    0.81563   0.70976   0.68320     20949\n",
      "weighted avg    0.81562   0.70977   0.68320     20949\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10468     7]\n",
      " [ 6073  4401]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagaimana cara penghantaran dan kos penghantar...</td>\n",
       "      <td>Ladam merupakan barang buatan yang lazimnya di...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apakah jenama bateri kereta yang disediakan ol...</td>\n",
       "      <td>Komik adalah sejenis seni visual yang menggabu...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apakah kawasan liputan untuk servis hantar bat...</td>\n",
       "      <td>untuk memecat Lawton, meninggalkan sekali lagi...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Bagaimana cara penghantaran dan kos penghantar...   \n",
       "1  Apakah jenama bateri kereta yang disediakan ol...   \n",
       "2  Apakah kawasan liputan untuk servis hantar bat...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Ladam merupakan barang buatan yang lazimnya di...      0  test   \n",
       "1  Komik adalah sejenis seni visual yang menggabu...      0  test   \n",
       "2  untuk memecat Lawton, meninggalkan sekali lagi...      0  test   \n",
       "\n",
       "    dataset_source  predicted_label  \n",
       "0  common-crawl-qa                0  \n",
       "1  common-crawl-qa                0  \n",
       "2  common-crawl-qa                0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenced_df.to_json(\n",
    "    f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl',\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sekapur sirih road dah</td>\n",
       "      <td>Abi Ahmad Furqan memang Barisan Nasional dah l...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Menangkan calon pakatan harapan di segi besar</td>\n",
       "      <td>Ismail sabri dan muhiadin</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norlelawati Sukiman amin pra</td>\n",
       "      <td>25k terbaik</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           query  \\\n",
       "0                         Sekapur sirih road dah   \n",
       "1  Menangkan calon pakatan harapan di segi besar   \n",
       "2                   Norlelawati Sukiman amin pra   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Abi Ahmad Furqan memang Barisan Nasional dah l...      0  test   \n",
       "1                          Ismail sabri dan muhiadin      0  test   \n",
       "2                                        25k terbaik      0  test   \n",
       "\n",
       "  dataset_source  \n",
       "0       facebook  \n",
       "1       facebook  \n",
       "2       facebook  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-facebook.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f1ef1ae1fc405b80ed34e4d6814d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t, max_length=512, truncation=True)\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        output = reranker_model(**padded).logits.view(-1, ).cpu().detach().float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9667777777777777\n",
      "ROC-AUC: 0.9643146852302846\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.94449   0.99682   0.96995     24205\n",
      "     class 1    0.99604   0.93181   0.96286     20795\n",
      "\n",
      "    accuracy                        0.96678     45000\n",
      "   macro avg    0.97027   0.96431   0.96640     45000\n",
      "weighted avg    0.96831   0.96678   0.96667     45000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[24128    77]\n",
      " [ 1418 19377]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sekapur sirih road dah</td>\n",
       "      <td>Abi Ahmad Furqan memang Barisan Nasional dah l...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Menangkan calon pakatan harapan di segi besar</td>\n",
       "      <td>Ismail sabri dan muhiadin</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norlelawati Sukiman amin pra</td>\n",
       "      <td>25k terbaik</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           query  \\\n",
       "0                         Sekapur sirih road dah   \n",
       "1  Menangkan calon pakatan harapan di segi besar   \n",
       "2                   Norlelawati Sukiman amin pra   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Abi Ahmad Furqan memang Barisan Nasional dah l...      0  test   \n",
       "1                          Ismail sabri dan muhiadin      0  test   \n",
       "2                                        25k terbaik      0  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0       facebook                0  \n",
       "1       facebook                0  \n",
       "2       facebook                0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-large-inferenced-facebook.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Hansard QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (12712, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Siapakah wakil rakyat untuk kawasan Kota Belud?</td>\n",
       "      <td>\\nii DR.07.12.2021 \\n\\n \\n58. YB. Dr. Kelvin Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berapa jumlah unit yang telah dibina oleh PR1M...</td>\n",
       "      <td>from this seller User Review Submit A Review O...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apakah langkah kerajaan yang hendak dikenakan ...</td>\n",
       "      <td>\\n8                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0    Siapakah wakil rakyat untuk kawasan Kota Belud?   \n",
       "1  Berapa jumlah unit yang telah dibina oleh PR1M...   \n",
       "2  Apakah langkah kerajaan yang hendak dikenakan ...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \\nii DR.07.12.2021 \\n\\n \\n58. YB. Dr. Kelvin Y...      1  test   \n",
       "1  from this seller User Review Submit A Review O...      0  test   \n",
       "2  \\n8                                           ...      1  test   \n",
       "\n",
       "  dataset_source  \n",
       "0     hansard-qa  \n",
       "1     hansard-qa  \n",
       "2     hansard-qa  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-hansard-qa.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a7e3ad87cc4ef3bd9c5e190162f3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t, max_length=512, truncation=True)\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        output = reranker_model(**padded).logits.view(-1, ).cpu().detach().float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8254405286343612\n",
      "ROC-AUC: 0.8254405286343613\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.74128   0.99984   0.85136      6356\n",
      "     class 1    0.99976   0.65104   0.78857      6356\n",
      "\n",
      "    accuracy                        0.82544     12712\n",
      "   macro avg    0.87052   0.82544   0.81996     12712\n",
      "weighted avg    0.87052   0.82544   0.81996     12712\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6355    1]\n",
      " [2218 4138]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Siapakah wakil rakyat untuk kawasan Kota Belud?</td>\n",
       "      <td>\\nii DR.07.12.2021 \\n\\n \\n58. YB. Dr. Kelvin Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berapa jumlah unit yang telah dibina oleh PR1M...</td>\n",
       "      <td>from this seller User Review Submit A Review O...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apakah langkah kerajaan yang hendak dikenakan ...</td>\n",
       "      <td>\\n8                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0    Siapakah wakil rakyat untuk kawasan Kota Belud?   \n",
       "1  Berapa jumlah unit yang telah dibina oleh PR1M...   \n",
       "2  Apakah langkah kerajaan yang hendak dikenakan ...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \\nii DR.07.12.2021 \\n\\n \\n58. YB. Dr. Kelvin Y...      1  test   \n",
       "1  from this seller User Review Submit A Review O...      0  test   \n",
       "2  \\n8                                           ...      1  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0     hansard-qa                1  \n",
       "1     hansard-qa                0  \n",
       "2     hansard-qa                0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-large-inferenced-hansard-qa.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.0 IIUM Confession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Means, dia berkurung dalam bilik, tarik muka d...</td>\n",
       "      <td>\"usia 20 an macam ni,memang kita perlukan sora...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saya selalu follow seorang perunding imej feme...</td>\n",
       "      <td>Aku sentiasa ikut seorang consultant image yan...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dan aku juga kasihan akan diriku sendiri. Di r...</td>\n",
       "      <td>And I also pity myself. In that house I was st...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Means, dia berkurung dalam bilik, tarik muka d...   \n",
       "1  Saya selalu follow seorang perunding imej feme...   \n",
       "2  Dan aku juga kasihan akan diriku sendiri. Di r...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \"usia 20 an macam ni,memang kita perlukan sora...      0  test   \n",
       "1  Aku sentiasa ikut seorang consultant image yan...      1  test   \n",
       "2  And I also pity myself. In that house I was st...      1  test   \n",
       "\n",
       "    dataset_source  \n",
       "0  iium-confession  \n",
       "1  iium-confession  \n",
       "2  iium-confession  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-iium-confession.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8888207135d418d984b3cfa8b005456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t, max_length=512, truncation=True)\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        output = reranker_model(**padded).logits.view(-1, ).cpu().detach().float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9958444444444444\n",
      "ROC-AUC: 0.9963640770090726\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99011   0.99809   0.99408     15743\n",
      "     class 1    0.99897   0.99463   0.99680     29257\n",
      "\n",
      "    accuracy                        0.99584     45000\n",
      "   macro avg    0.99454   0.99636   0.99544     45000\n",
      "weighted avg    0.99587   0.99584   0.99585     45000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15713    30]\n",
      " [  157 29100]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Means, dia berkurung dalam bilik, tarik muka d...</td>\n",
       "      <td>\"usia 20 an macam ni,memang kita perlukan sora...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saya selalu follow seorang perunding imej feme...</td>\n",
       "      <td>Aku sentiasa ikut seorang consultant image yan...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dan aku juga kasihan akan diriku sendiri. Di r...</td>\n",
       "      <td>And I also pity myself. In that house I was st...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Means, dia berkurung dalam bilik, tarik muka d...   \n",
       "1  Saya selalu follow seorang perunding imej feme...   \n",
       "2  Dan aku juga kasihan akan diriku sendiri. Di r...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \"usia 20 an macam ni,memang kita perlukan sora...      0  test   \n",
       "1  Aku sentiasa ikut seorang consultant image yan...      1  test   \n",
       "2  And I also pity myself. In that house I was st...      1  test   \n",
       "\n",
       "    dataset_source  predicted_label  \n",
       "0  iium-confession                0  \n",
       "1  iium-confession                1  \n",
       "2  iium-confession                1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-large-inferenced-iium-confession.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 B Cari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (44910, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello. I am a student. Every time I need to wr...</td>\n",
       "      <td>Hello. Im a student. If I need to write an ess...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>betul ke boleh tapis? dan filter dalam tu mest...</td>\n",
       "      <td>Is it true that it can be filtered? And the fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jangan dia main campak masuk tong sampah bila ...</td>\n",
       "      <td>mmmeeeeowwwwwwwwwwwwwwww</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hello. I am a student. Every time I need to wr...   \n",
       "1  betul ke boleh tapis? dan filter dalam tu mest...   \n",
       "2  Jangan dia main campak masuk tong sampah bila ...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Hello. Im a student. If I need to write an ess...      1  test   \n",
       "1  Is it true that it can be filtered? And the fi...      1  test   \n",
       "2                           mmmeeeeowwwwwwwwwwwwwwww      0  test   \n",
       "\n",
       "         dataset_source  \n",
       "0  mining-b-cari-com-my  \n",
       "1  mining-b-cari-com-my  \n",
       "2  mining-b-cari-com-my  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-mining-b-cari-com-my.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd79d29996249f5944442d8cbf2c362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4491 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t, max_length=512, truncation=True)\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        output = reranker_model(**padded).logits.view(-1, ).cpu().detach().float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9723669561344912\n",
      "ROC-AUC: 0.9742322941729378\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.94553   0.99734   0.97074     20642\n",
      "     class 1    0.99762   0.95113   0.97382     24268\n",
      "\n",
      "    accuracy                        0.97237     44910\n",
      "   macro avg    0.97158   0.97423   0.97228     44910\n",
      "weighted avg    0.97368   0.97237   0.97241     44910\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20587    55]\n",
      " [ 1186 23082]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello. I am a student. Every time I need to wr...</td>\n",
       "      <td>Hello. Im a student. If I need to write an ess...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>betul ke boleh tapis? dan filter dalam tu mest...</td>\n",
       "      <td>Is it true that it can be filtered? And the fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jangan dia main campak masuk tong sampah bila ...</td>\n",
       "      <td>mmmeeeeowwwwwwwwwwwwwwww</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hello. I am a student. Every time I need to wr...   \n",
       "1  betul ke boleh tapis? dan filter dalam tu mest...   \n",
       "2  Jangan dia main campak masuk tong sampah bila ...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Hello. Im a student. If I need to write an ess...      1  test   \n",
       "1  Is it true that it can be filtered? And the fi...      1  test   \n",
       "2                           mmmeeeeowwwwwwwwwwwwwwww      0  test   \n",
       "\n",
       "         dataset_source  predicted_label  \n",
       "0  mining-b-cari-com-my                1  \n",
       "1  mining-b-cari-com-my                1  \n",
       "2  mining-b-cari-com-my                0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-large-inferenced-mining-b-cari-com-my.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.0 Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (44123, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sektor pertanian dijangka pulih pada 2019 deng...</td>\n",
       "      <td>KUALA LUMPUR: Sektor pertanian dijangka pulih ...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaysia Today, a Malaysian news site, has bee...</td>\n",
       "      <td>Tolong lah gais, aku nasihatkan tolong kunci p...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the Malaysian General Election (GE15), no p...</td>\n",
       "      <td>PUTRAJAYA: Tiada mana-mana parti memperoleh 50...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Sektor pertanian dijangka pulih pada 2019 deng...   \n",
       "1  Malaysia Today, a Malaysian news site, has bee...   \n",
       "2  In the Malaysian General Election (GE15), no p...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  KUALA LUMPUR: Sektor pertanian dijangka pulih ...      1  test   \n",
       "1  Tolong lah gais, aku nasihatkan tolong kunci p...      0  test   \n",
       "2  PUTRAJAYA: Tiada mana-mana parti memperoleh 50...      1  test   \n",
       "\n",
       "         dataset_source  \n",
       "0  mining-summarization  \n",
       "1  mining-summarization  \n",
       "2  mining-summarization  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-mining-summarization.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca4d222439d4b208a93e881370d29f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t, max_length=512, truncation=True)\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        output = reranker_model(**padded).logits.view(-1, ).cpu().detach().float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9526550778505541\n",
      "ROC-AUC: 0.9305571647265575\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.97857   0.96406   0.97126     36614\n",
      "     class 1    0.83656   0.89706   0.86575      7509\n",
      "\n",
      "    accuracy                        0.95266     44123\n",
      "   macro avg    0.90757   0.93056   0.91851     44123\n",
      "weighted avg    0.95440   0.95266   0.95330     44123\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[35298  1316]\n",
      " [  773  6736]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sektor pertanian dijangka pulih pada 2019 deng...</td>\n",
       "      <td>KUALA LUMPUR: Sektor pertanian dijangka pulih ...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaysia Today, a Malaysian news site, has bee...</td>\n",
       "      <td>Tolong lah gais, aku nasihatkan tolong kunci p...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the Malaysian General Election (GE15), no p...</td>\n",
       "      <td>PUTRAJAYA: Tiada mana-mana parti memperoleh 50...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Sektor pertanian dijangka pulih pada 2019 deng...   \n",
       "1  Malaysia Today, a Malaysian news site, has bee...   \n",
       "2  In the Malaysian General Election (GE15), no p...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  KUALA LUMPUR: Sektor pertanian dijangka pulih ...      1  test   \n",
       "1  Tolong lah gais, aku nasihatkan tolong kunci p...      0  test   \n",
       "2  PUTRAJAYA: Tiada mana-mana parti memperoleh 50...      1  test   \n",
       "\n",
       "         dataset_source  predicted_label  \n",
       "0  mining-summarization                1  \n",
       "1  mining-summarization                0  \n",
       "2  mining-summarization                1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-large-inferenced-mining-summarization.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.0 News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bridgerton: sex, gossip and race in Regency Lo...</td>\n",
       "      <td>THE appointment of Najib Razak as chairman of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAS minta putus dengan PKR kerana Selena Gomez</td>\n",
       "      <td>\\n(Focus Malaysia)  Legal practitioner Khairu...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harga MSM dijangka terus meningkat</td>\n",
       "      <td>LONDON, Feb 9  Lewis Hamilton has signed a o...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Bridgerton: sex, gossip and race in Regency Lo...   \n",
       "1     PAS minta putus dengan PKR kerana Selena Gomez   \n",
       "2                 Harga MSM dijangka terus meningkat   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  THE appointment of Najib Razak as chairman of ...      0  test   \n",
       "1  \\n(Focus Malaysia)  Legal practitioner Khairu...      0  test   \n",
       "2   LONDON, Feb 9  Lewis Hamilton has signed a o...      0  test   \n",
       "\n",
       "  dataset_source  \n",
       "0           news  \n",
       "1           news  \n",
       "2           news  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-news.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ab63ebcf594f9abf96b6dbf08566c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t, max_length=512, truncation=True)\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        output = reranker_model(**padded).logits.view(-1, ).cpu().detach().float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9737777777777777\n",
      "ROC-AUC: 0.9414455730734652\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.97862   0.99012   0.98434     37446\n",
      "     class 1    0.94799   0.89277   0.91955      7554\n",
      "\n",
      "    accuracy                        0.97378     45000\n",
      "   macro avg    0.96330   0.94145   0.95194     45000\n",
      "weighted avg    0.97348   0.97378   0.97346     45000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[37076   370]\n",
      " [  810  6744]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bridgerton: sex, gossip and race in Regency Lo...</td>\n",
       "      <td>THE appointment of Najib Razak as chairman of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAS minta putus dengan PKR kerana Selena Gomez</td>\n",
       "      <td>\\n(Focus Malaysia)  Legal practitioner Khairu...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harga MSM dijangka terus meningkat</td>\n",
       "      <td>LONDON, Feb 9  Lewis Hamilton has signed a o...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Bridgerton: sex, gossip and race in Regency Lo...   \n",
       "1     PAS minta putus dengan PKR kerana Selena Gomez   \n",
       "2                 Harga MSM dijangka terus meningkat   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  THE appointment of Najib Razak as chairman of ...      0  test   \n",
       "1  \\n(Focus Malaysia)  Legal practitioner Khairu...      0  test   \n",
       "2   LONDON, Feb 9  Lewis Hamilton has signed a o...      0  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0           news                0  \n",
       "1           news                0  \n",
       "2           news                0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-large-inferenced-news.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.0 Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@nickgle_ Sugarbun tapi nadai manuk tadi.</td>\n",
       "      <td>@nickgle_ Sugarbun tapi xda ayam td</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semua laki laki sama aja.\\nTapi kalo kamu sama...</td>\n",
       "      <td>@hardliffee Jngan terlalu larut tidurnya yaa</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11:16am PLUS@E1 :  Kerja penyelenggaraan KM 23...</td>\n",
       "      <td>Maintenance work KM 231.0 - KM 233.0 South fro...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0         @nickgle_ Sugarbun tapi nadai manuk tadi.    \n",
       "1  Semua laki laki sama aja.\\nTapi kalo kamu sama...   \n",
       "2  11:16am PLUS@E1 :  Kerja penyelenggaraan KM 23...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0                @nickgle_ Sugarbun tapi xda ayam td      1  test   \n",
       "1       @hardliffee Jngan terlalu larut tidurnya yaa      0  test   \n",
       "2  Maintenance work KM 231.0 - KM 233.0 South fro...      1  test   \n",
       "\n",
       "  dataset_source  \n",
       "0        twitter  \n",
       "1        twitter  \n",
       "2        twitter  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-twitter.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930ce2eff93745e4b4f57bb14dcbd795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t, max_length=512, truncation=True)\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        output = reranker_model(**padded).logits.view(-1, ).cpu().detach().float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9765333333333334\n",
      "ROC-AUC: 0.9796844940361678\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.94737   1.00000   0.97298     19010\n",
      "     class 1    1.00000   0.95937   0.97926     25990\n",
      "\n",
      "    accuracy                        0.97653     45000\n",
      "   macro avg    0.97369   0.97968   0.97612     45000\n",
      "weighted avg    0.97777   0.97653   0.97661     45000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19010     0]\n",
      " [ 1056 24934]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@nickgle_ Sugarbun tapi nadai manuk tadi.</td>\n",
       "      <td>@nickgle_ Sugarbun tapi xda ayam td</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semua laki laki sama aja.\\nTapi kalo kamu sama...</td>\n",
       "      <td>@hardliffee Jngan terlalu larut tidurnya yaa</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11:16am PLUS@E1 :  Kerja penyelenggaraan KM 23...</td>\n",
       "      <td>Maintenance work KM 231.0 - KM 233.0 South fro...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0         @nickgle_ Sugarbun tapi nadai manuk tadi.    \n",
       "1  Semua laki laki sama aja.\\nTapi kalo kamu sama...   \n",
       "2  11:16am PLUS@E1 :  Kerja penyelenggaraan KM 23...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0                @nickgle_ Sugarbun tapi xda ayam td      1  test   \n",
       "1       @hardliffee Jngan terlalu larut tidurnya yaa      0  test   \n",
       "2  Maintenance work KM 231.0 - KM 233.0 South fro...      1  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0        twitter                0  \n",
       "1        twitter                0  \n",
       "2        twitter                1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-large-inferenced-twitter.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.0 Wikipedia QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (32903, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apakah penyakit yang diderita oleh Sharielda?</td>\n",
       "      <td>\\nDR. 26.7.2022 103 \\n\\n \\nkemungkinan daripad...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siapakah komposer muda yang Chrisye dekati unt...</td>\n",
       "      <td>Guruh, dan beliau juga akan berjumpa dengannya...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siapakah yang menfailkan petisyen untuk menunt...</td>\n",
       "      <td>\\n56   DR. 10.7.2019 \\n\\n \\n\\n \\n\\nTuan Yang d...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0      Apakah penyakit yang diderita oleh Sharielda?   \n",
       "1  Siapakah komposer muda yang Chrisye dekati unt...   \n",
       "2  Siapakah yang menfailkan petisyen untuk menunt...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \\nDR. 26.7.2022 103 \\n\\n \\nkemungkinan daripad...      0  test   \n",
       "1  Guruh, dan beliau juga akan berjumpa dengannya...      1  test   \n",
       "2  \\n56   DR. 10.7.2019 \\n\\n \\n\\n \\n\\nTuan Yang d...      0  test   \n",
       "\n",
       "  dataset_source  \n",
       "0   wikipedia-qa  \n",
       "1   wikipedia-qa  \n",
       "2   wikipedia-qa  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-wikipedia-qa.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584e71a9ac294d48af4921b055db6a17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t, max_length=512, truncation=True)\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        output = reranker_model(**padded).logits.view(-1, ).cpu().detach().float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8710148010819682\n",
      "ROC-AUC: 0.8710109122031797\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.79542   0.99897   0.88565     16452\n",
      "     class 1    0.99861   0.74306   0.85208     16451\n",
      "\n",
      "    accuracy                        0.87101     32903\n",
      "   macro avg    0.89702   0.87101   0.86887     32903\n",
      "weighted avg    0.89701   0.87101   0.86887     32903\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16435    17]\n",
      " [ 4227 12224]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apakah penyakit yang diderita oleh Sharielda?</td>\n",
       "      <td>\\nDR. 26.7.2022 103 \\n\\n \\nkemungkinan daripad...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siapakah komposer muda yang Chrisye dekati unt...</td>\n",
       "      <td>Guruh, dan beliau juga akan berjumpa dengannya...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siapakah yang menfailkan petisyen untuk menunt...</td>\n",
       "      <td>\\n56   DR. 10.7.2019 \\n\\n \\n\\n \\n\\nTuan Yang d...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0      Apakah penyakit yang diderita oleh Sharielda?   \n",
       "1  Siapakah komposer muda yang Chrisye dekati unt...   \n",
       "2  Siapakah yang menfailkan petisyen untuk menunt...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \\nDR. 26.7.2022 103 \\n\\n \\nkemungkinan daripad...      0  test   \n",
       "1  Guruh, dan beliau juga akan berjumpa dengannya...      1  test   \n",
       "2  \\n56   DR. 10.7.2019 \\n\\n \\n\\n \\n\\nTuan Yang d...      0  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0   wikipedia-qa                0  \n",
       "1   wikipedia-qa                1  \n",
       "2   wikipedia-qa                0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-large-inferenced-wikipedia-qa.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
