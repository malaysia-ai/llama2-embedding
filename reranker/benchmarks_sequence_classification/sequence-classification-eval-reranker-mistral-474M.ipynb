{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import flash_attn\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score, classification_report, \\\n",
    "                            roc_auc_score, confusion_matrix\n",
    "\n",
    "model_used = '474M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05d1db524ec4badb5eb273ca3a8214e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/747 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baeb931ce7334b54844139497ab9a27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/884M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n"
     ]
    }
   ],
   "source": [
    "# load reranker model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mesolitica/reranker-malaysian-mistral-474M-32k\")\n",
    "reranker_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"mesolitica/reranker-malaysian-mistral-474M-32k\",\n",
    "    use_flash_attention_2 = True,\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    use_cache = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push model to the GPU!\n",
    "_ = reranker_model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr 26 15:47:06 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA A100 80GB PCIe          On  | 00000001:00:00.0 Off |                    0 |\r\n",
      "| N/A   38C    P0              68W / 300W |   6767MiB / 81920MiB |      0%      Default |\r\n",
      "|                                         |                      |             Disabled |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Common Crawl QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (20949, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagaimana cara penghantaran dan kos penghantar...</td>\n",
       "      <td>Ladam merupakan barang buatan yang lazimnya di...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apakah jenama bateri kereta yang disediakan ol...</td>\n",
       "      <td>Komik adalah sejenis seni visual yang menggabu...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apakah kawasan liputan untuk servis hantar bat...</td>\n",
       "      <td>untuk memecat Lawton, meninggalkan sekali lagi...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Bagaimana cara penghantaran dan kos penghantar...   \n",
       "1  Apakah jenama bateri kereta yang disediakan ol...   \n",
       "2  Apakah kawasan liputan untuk servis hantar bat...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Ladam merupakan barang buatan yang lazimnya di...      0  test   \n",
       "1  Komik adalah sejenis seni visual yang menggabu...      0  test   \n",
       "2  untuk memecat Lawton, meninggalkan sekali lagi...      0  test   \n",
       "\n",
       "    dataset_source  \n",
       "0  common-crawl-qa  \n",
       "1  common-crawl-qa  \n",
       "2  common-crawl-qa  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-common-crawl-qa.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb70b44433f4e27bda11aa5e8ea127e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2095 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t)\n",
    "            input_ids.pop('token_type_ids')\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        scores.extend(reranker_model(**padded).logits.cpu().detach().float().numpy().argmax(axis = 1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9947968876796028\n",
      "ROC-AUC: 0.9947968717173516\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99447   0.99513   0.99480     10475\n",
      "     class 1    0.99513   0.99446   0.99479     10474\n",
      "\n",
      "    accuracy                        0.99480     20949\n",
      "   macro avg    0.99480   0.99480   0.99480     20949\n",
      "weighted avg    0.99480   0.99480   0.99480     20949\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10424    51]\n",
      " [   58 10416]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagaimana cara penghantaran dan kos penghantar...</td>\n",
       "      <td>Ladam merupakan barang buatan yang lazimnya di...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apakah jenama bateri kereta yang disediakan ol...</td>\n",
       "      <td>Komik adalah sejenis seni visual yang menggabu...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apakah kawasan liputan untuk servis hantar bat...</td>\n",
       "      <td>untuk memecat Lawton, meninggalkan sekali lagi...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Bagaimana cara penghantaran dan kos penghantar...   \n",
       "1  Apakah jenama bateri kereta yang disediakan ol...   \n",
       "2  Apakah kawasan liputan untuk servis hantar bat...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Ladam merupakan barang buatan yang lazimnya di...      0  test   \n",
       "1  Komik adalah sejenis seni visual yang menggabu...      0  test   \n",
       "2  untuk memecat Lawton, meninggalkan sekali lagi...      0  test   \n",
       "\n",
       "    dataset_source  predicted_label  \n",
       "0  common-crawl-qa                0  \n",
       "1  common-crawl-qa                0  \n",
       "2  common-crawl-qa                0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenced_df.to_json(\n",
    "    f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl',\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sekapur sirih road dah</td>\n",
       "      <td>Abi Ahmad Furqan memang Barisan Nasional dah l...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Menangkan calon pakatan harapan di segi besar</td>\n",
       "      <td>Ismail sabri dan muhiadin</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norlelawati Sukiman amin pra</td>\n",
       "      <td>25k terbaik</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           query  \\\n",
       "0                         Sekapur sirih road dah   \n",
       "1  Menangkan calon pakatan harapan di segi besar   \n",
       "2                   Norlelawati Sukiman amin pra   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Abi Ahmad Furqan memang Barisan Nasional dah l...      0  test   \n",
       "1                          Ismail sabri dan muhiadin      0  test   \n",
       "2                                        25k terbaik      0  test   \n",
       "\n",
       "  dataset_source  \n",
       "0       facebook  \n",
       "1       facebook  \n",
       "2       facebook  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-facebook.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d36748f522674b1f97a8f17f2e5c1152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t)\n",
    "            input_ids.pop('token_type_ids')\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        scores.extend(reranker_model(**padded).logits.cpu().detach().float().numpy().argmax(axis = 1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9892222222222222\n",
      "ROC-AUC: 0.9895004047687365\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99408   0.98583   0.98994     24205\n",
      "     class 1    0.98366   0.99317   0.98839     20795\n",
      "\n",
      "    accuracy                        0.98922     45000\n",
      "   macro avg    0.98887   0.98950   0.98917     45000\n",
      "weighted avg    0.98927   0.98922   0.98923     45000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[23862   343]\n",
      " [  142 20653]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sekapur sirih road dah</td>\n",
       "      <td>Abi Ahmad Furqan memang Barisan Nasional dah l...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Menangkan calon pakatan harapan di segi besar</td>\n",
       "      <td>Ismail sabri dan muhiadin</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norlelawati Sukiman amin pra</td>\n",
       "      <td>25k terbaik</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           query  \\\n",
       "0                         Sekapur sirih road dah   \n",
       "1  Menangkan calon pakatan harapan di segi besar   \n",
       "2                   Norlelawati Sukiman amin pra   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Abi Ahmad Furqan memang Barisan Nasional dah l...      0  test   \n",
       "1                          Ismail sabri dan muhiadin      0  test   \n",
       "2                                        25k terbaik      0  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0       facebook                0  \n",
       "1       facebook                0  \n",
       "2       facebook                0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenced_df.to_json(\n",
    "    f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl',\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Hansard QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (12712, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Siapakah wakil rakyat untuk kawasan Kota Belud?</td>\n",
       "      <td>\\nii DR.07.12.2021 \\n\\n \\n58. YB. Dr. Kelvin Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berapa jumlah unit yang telah dibina oleh PR1M...</td>\n",
       "      <td>from this seller User Review Submit A Review O...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apakah langkah kerajaan yang hendak dikenakan ...</td>\n",
       "      <td>\\n8                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0    Siapakah wakil rakyat untuk kawasan Kota Belud?   \n",
       "1  Berapa jumlah unit yang telah dibina oleh PR1M...   \n",
       "2  Apakah langkah kerajaan yang hendak dikenakan ...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \\nii DR.07.12.2021 \\n\\n \\n58. YB. Dr. Kelvin Y...      1  test   \n",
       "1  from this seller User Review Submit A Review O...      0  test   \n",
       "2  \\n8                                           ...      1  test   \n",
       "\n",
       "  dataset_source  \n",
       "0     hansard-qa  \n",
       "1     hansard-qa  \n",
       "2     hansard-qa  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-hansard-qa.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f17309695ec141f9b55bcfbc6e449e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t)\n",
    "            input_ids.pop('token_type_ids')\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        scores.extend(reranker_model(**padded).logits.cpu().detach().float().numpy().argmax(axis = 1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9911894273127754\n",
      "ROC-AUC: 0.9911894273127753\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99524   0.98710   0.99115      6356\n",
      "     class 1    0.98720   0.99528   0.99123      6356\n",
      "\n",
      "    accuracy                        0.99119     12712\n",
      "   macro avg    0.99122   0.99119   0.99119     12712\n",
      "weighted avg    0.99122   0.99119   0.99119     12712\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[6274   82]\n",
      " [  30 6326]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Siapakah wakil rakyat untuk kawasan Kota Belud?</td>\n",
       "      <td>\\nii DR.07.12.2021 \\n\\n \\n58. YB. Dr. Kelvin Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berapa jumlah unit yang telah dibina oleh PR1M...</td>\n",
       "      <td>from this seller User Review Submit A Review O...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apakah langkah kerajaan yang hendak dikenakan ...</td>\n",
       "      <td>\\n8                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0    Siapakah wakil rakyat untuk kawasan Kota Belud?   \n",
       "1  Berapa jumlah unit yang telah dibina oleh PR1M...   \n",
       "2  Apakah langkah kerajaan yang hendak dikenakan ...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \\nii DR.07.12.2021 \\n\\n \\n58. YB. Dr. Kelvin Y...      1  test   \n",
       "1  from this seller User Review Submit A Review O...      0  test   \n",
       "2  \\n8                                           ...      1  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0     hansard-qa                1  \n",
       "1     hansard-qa                0  \n",
       "2     hansard-qa                1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenced_df.to_json(\n",
    "    f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl',\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.0 IIUM Confession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Means, dia berkurung dalam bilik, tarik muka d...</td>\n",
       "      <td>\"usia 20 an macam ni,memang kita perlukan sora...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saya selalu follow seorang perunding imej feme...</td>\n",
       "      <td>Aku sentiasa ikut seorang consultant image yan...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dan aku juga kasihan akan diriku sendiri. Di r...</td>\n",
       "      <td>And I also pity myself. In that house I was st...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Means, dia berkurung dalam bilik, tarik muka d...   \n",
       "1  Saya selalu follow seorang perunding imej feme...   \n",
       "2  Dan aku juga kasihan akan diriku sendiri. Di r...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \"usia 20 an macam ni,memang kita perlukan sora...      0  test   \n",
       "1  Aku sentiasa ikut seorang consultant image yan...      1  test   \n",
       "2  And I also pity myself. In that house I was st...      1  test   \n",
       "\n",
       "    dataset_source  \n",
       "0  iium-confession  \n",
       "1  iium-confession  \n",
       "2  iium-confession  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-iium-confession.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e02be76bcf4f71bea8210d42be85d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t)\n",
    "            input_ids.pop('token_type_ids')\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        scores.extend(reranker_model(**padded).logits.cpu().detach().float().numpy().argmax(axis = 1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9986888888888888\n",
      "ROC-AUC: 0.9987423005524895\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99734   0.99892   0.99813     15743\n",
      "     class 1    0.99942   0.99856   0.99899     29257\n",
      "\n",
      "    accuracy                        0.99869     45000\n",
      "   macro avg    0.99838   0.99874   0.99856     45000\n",
      "weighted avg    0.99869   0.99869   0.99869     45000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[15726    17]\n",
      " [   42 29215]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Means, dia berkurung dalam bilik, tarik muka d...</td>\n",
       "      <td>\"usia 20 an macam ni,memang kita perlukan sora...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saya selalu follow seorang perunding imej feme...</td>\n",
       "      <td>Aku sentiasa ikut seorang consultant image yan...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dan aku juga kasihan akan diriku sendiri. Di r...</td>\n",
       "      <td>And I also pity myself. In that house I was st...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Means, dia berkurung dalam bilik, tarik muka d...   \n",
       "1  Saya selalu follow seorang perunding imej feme...   \n",
       "2  Dan aku juga kasihan akan diriku sendiri. Di r...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \"usia 20 an macam ni,memang kita perlukan sora...      0  test   \n",
       "1  Aku sentiasa ikut seorang consultant image yan...      1  test   \n",
       "2  And I also pity myself. In that house I was st...      1  test   \n",
       "\n",
       "    dataset_source  predicted_label  \n",
       "0  iium-confession                0  \n",
       "1  iium-confession                1  \n",
       "2  iium-confession                1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenced_df.to_json(\n",
    "    f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl',\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 B Cari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (44910, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello. I am a student. Every time I need to wr...</td>\n",
       "      <td>Hello. Im a student. If I need to write an ess...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>betul ke boleh tapis? dan filter dalam tu mest...</td>\n",
       "      <td>Is it true that it can be filtered? And the fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jangan dia main campak masuk tong sampah bila ...</td>\n",
       "      <td>mmmeeeeowwwwwwwwwwwwwwww</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hello. I am a student. Every time I need to wr...   \n",
       "1  betul ke boleh tapis? dan filter dalam tu mest...   \n",
       "2  Jangan dia main campak masuk tong sampah bila ...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Hello. Im a student. If I need to write an ess...      1  test   \n",
       "1  Is it true that it can be filtered? And the fi...      1  test   \n",
       "2                           mmmeeeeowwwwwwwwwwwwwwww      0  test   \n",
       "\n",
       "         dataset_source  \n",
       "0  mining-b-cari-com-my  \n",
       "1  mining-b-cari-com-my  \n",
       "2  mining-b-cari-com-my  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-mining-b-cari-com-my.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35905e42d5414b838f5c1ef496b399e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4491 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t)\n",
    "            input_ids.pop('token_type_ids')\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        scores.extend(reranker_model(**padded).logits.cpu().detach().float().numpy().argmax(axis = 1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9942329102649744\n",
      "ROC-AUC: 0.9942873584060126\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99251   0.99496   0.99373     20642\n",
      "     class 1    0.99571   0.99361   0.99466     24268\n",
      "\n",
      "    accuracy                        0.99423     44910\n",
      "   macro avg    0.99411   0.99429   0.99420     44910\n",
      "weighted avg    0.99424   0.99423   0.99423     44910\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20538   104]\n",
      " [  155 24113]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello. I am a student. Every time I need to wr...</td>\n",
       "      <td>Hello. Im a student. If I need to write an ess...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>betul ke boleh tapis? dan filter dalam tu mest...</td>\n",
       "      <td>Is it true that it can be filtered? And the fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jangan dia main campak masuk tong sampah bila ...</td>\n",
       "      <td>mmmeeeeowwwwwwwwwwwwwwww</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hello. I am a student. Every time I need to wr...   \n",
       "1  betul ke boleh tapis? dan filter dalam tu mest...   \n",
       "2  Jangan dia main campak masuk tong sampah bila ...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Hello. Im a student. If I need to write an ess...      1  test   \n",
       "1  Is it true that it can be filtered? And the fi...      1  test   \n",
       "2                           mmmeeeeowwwwwwwwwwwwwwww      0  test   \n",
       "\n",
       "         dataset_source  predicted_label  \n",
       "0  mining-b-cari-com-my                1  \n",
       "1  mining-b-cari-com-my                1  \n",
       "2  mining-b-cari-com-my                0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenced_df.to_json(\n",
    "    f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl',\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.0 Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (44123, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sektor pertanian dijangka pulih pada 2019 deng...</td>\n",
       "      <td>KUALA LUMPUR: Sektor pertanian dijangka pulih ...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaysia Today, a Malaysian news site, has bee...</td>\n",
       "      <td>Tolong lah gais, aku nasihatkan tolong kunci p...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the Malaysian General Election (GE15), no p...</td>\n",
       "      <td>PUTRAJAYA: Tiada mana-mana parti memperoleh 50...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Sektor pertanian dijangka pulih pada 2019 deng...   \n",
       "1  Malaysia Today, a Malaysian news site, has bee...   \n",
       "2  In the Malaysian General Election (GE15), no p...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  KUALA LUMPUR: Sektor pertanian dijangka pulih ...      1  test   \n",
       "1  Tolong lah gais, aku nasihatkan tolong kunci p...      0  test   \n",
       "2  PUTRAJAYA: Tiada mana-mana parti memperoleh 50...      1  test   \n",
       "\n",
       "         dataset_source  \n",
       "0  mining-summarization  \n",
       "1  mining-summarization  \n",
       "2  mining-summarization  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-mining-summarization.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a090f42cf614d659f84fc9a05947cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22062 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 2\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t)\n",
    "            input_ids.pop('token_type_ids')\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        scores.extend(reranker_model(**padded).logits.cpu().detach().float().numpy().argmax(axis = 1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    36614\n",
       "1     7509\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9968723794846225\n",
      "ROC-AUC: 0.9921872271509471\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99695   0.99929   0.99812     36614\n",
      "     class 1    0.99650   0.98508   0.99076      7509\n",
      "\n",
      "    accuracy                        0.99687     44123\n",
      "   macro avg    0.99672   0.99219   0.99444     44123\n",
      "weighted avg    0.99687   0.99687   0.99687     44123\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[36588    26]\n",
      " [  112  7397]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenced_df.to_json(\n",
    "    f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl',\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.0 News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bridgerton: sex, gossip and race in Regency Lo...</td>\n",
       "      <td>THE appointment of Najib Razak as chairman of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAS minta putus dengan PKR kerana Selena Gomez</td>\n",
       "      <td>\\n(Focus Malaysia)  Legal practitioner Khairu...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harga MSM dijangka terus meningkat</td>\n",
       "      <td>LONDON, Feb 9  Lewis Hamilton has signed a o...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Bridgerton: sex, gossip and race in Regency Lo...   \n",
       "1     PAS minta putus dengan PKR kerana Selena Gomez   \n",
       "2                 Harga MSM dijangka terus meningkat   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  THE appointment of Najib Razak as chairman of ...      0  test   \n",
       "1  \\n(Focus Malaysia)  Legal practitioner Khairu...      0  test   \n",
       "2   LONDON, Feb 9  Lewis Hamilton has signed a o...      0  test   \n",
       "\n",
       "  dataset_source  \n",
       "0           news  \n",
       "1           news  \n",
       "2           news  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-news.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f5510db2bf477e9bdc17a0b2ad3fb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 5\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t)\n",
    "            input_ids.pop('token_type_ids')\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        scores.extend(reranker_model(**padded).logits.cpu().detach().float().numpy().argmax(axis = 1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9939111111111111\n",
      "ROC-AUC: 0.9861437536507428\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99486   0.99784   0.99635     37446\n",
      "     class 1    0.98912   0.97445   0.98173      7554\n",
      "\n",
      "    accuracy                        0.99391     45000\n",
      "   macro avg    0.99199   0.98614   0.98904     45000\n",
      "weighted avg    0.99390   0.99391   0.99389     45000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[37365    81]\n",
      " [  193  7361]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bridgerton: sex, gossip and race in Regency Lo...</td>\n",
       "      <td>THE appointment of Najib Razak as chairman of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAS minta putus dengan PKR kerana Selena Gomez</td>\n",
       "      <td>\\n(Focus Malaysia)  Legal practitioner Khairu...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harga MSM dijangka terus meningkat</td>\n",
       "      <td>LONDON, Feb 9  Lewis Hamilton has signed a o...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Bridgerton: sex, gossip and race in Regency Lo...   \n",
       "1     PAS minta putus dengan PKR kerana Selena Gomez   \n",
       "2                 Harga MSM dijangka terus meningkat   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  THE appointment of Najib Razak as chairman of ...      0  test   \n",
       "1  \\n(Focus Malaysia)  Legal practitioner Khairu...      0  test   \n",
       "2   LONDON, Feb 9  Lewis Hamilton has signed a o...      0  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0           news                0  \n",
       "1           news                0  \n",
       "2           news                0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenced_df.to_json(\n",
    "    f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl',\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.0 Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@nickgle_ Sugarbun tapi nadai manuk tadi.</td>\n",
       "      <td>@nickgle_ Sugarbun tapi xda ayam td</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semua laki laki sama aja.\\nTapi kalo kamu sama...</td>\n",
       "      <td>@hardliffee Jngan terlalu larut tidurnya yaa</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11:16am PLUS@E1 :  Kerja penyelenggaraan KM 23...</td>\n",
       "      <td>Maintenance work KM 231.0 - KM 233.0 South fro...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0         @nickgle_ Sugarbun tapi nadai manuk tadi.    \n",
       "1  Semua laki laki sama aja.\\nTapi kalo kamu sama...   \n",
       "2  11:16am PLUS@E1 :  Kerja penyelenggaraan KM 23...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0                @nickgle_ Sugarbun tapi xda ayam td      1  test   \n",
       "1       @hardliffee Jngan terlalu larut tidurnya yaa      0  test   \n",
       "2  Maintenance work KM 231.0 - KM 233.0 South fro...      1  test   \n",
       "\n",
       "  dataset_source  \n",
       "0        twitter  \n",
       "1        twitter  \n",
       "2        twitter  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-twitter.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed75f81e88c6410ba627844caf908eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t)\n",
    "            input_ids.pop('token_type_ids')\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        scores.extend(reranker_model(**padded).logits.cpu().detach().float().numpy().argmax(axis = 1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9966444444444444\n",
      "ROC-AUC: 0.9965723169940125\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99595   0.99611   0.99603     19010\n",
      "     class 1    0.99715   0.99704   0.99709     25990\n",
      "\n",
      "    accuracy                        0.99664     45000\n",
      "   macro avg    0.99655   0.99657   0.99656     45000\n",
      "weighted avg    0.99664   0.99664   0.99664     45000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18936    74]\n",
      " [   77 25913]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@nickgle_ Sugarbun tapi nadai manuk tadi.</td>\n",
       "      <td>@nickgle_ Sugarbun tapi xda ayam td</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semua laki laki sama aja.\\nTapi kalo kamu sama...</td>\n",
       "      <td>@hardliffee Jngan terlalu larut tidurnya yaa</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11:16am PLUS@E1 :  Kerja penyelenggaraan KM 23...</td>\n",
       "      <td>Maintenance work KM 231.0 - KM 233.0 South fro...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0         @nickgle_ Sugarbun tapi nadai manuk tadi.    \n",
       "1  Semua laki laki sama aja.\\nTapi kalo kamu sama...   \n",
       "2  11:16am PLUS@E1 :  Kerja penyelenggaraan KM 23...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0                @nickgle_ Sugarbun tapi xda ayam td      1  test   \n",
       "1       @hardliffee Jngan terlalu larut tidurnya yaa      0  test   \n",
       "2  Maintenance work KM 231.0 - KM 233.0 South fro...      1  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0        twitter                1  \n",
       "1        twitter                0  \n",
       "2        twitter                1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenced_df.to_json(\n",
    "    f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl',\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.0 Wikipedia QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (32903, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apakah penyakit yang diderita oleh Sharielda?</td>\n",
       "      <td>\\nDR. 26.7.2022 103 \\n\\n \\nkemungkinan daripad...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siapakah komposer muda yang Chrisye dekati unt...</td>\n",
       "      <td>Guruh, dan beliau juga akan berjumpa dengannya...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siapakah yang menfailkan petisyen untuk menunt...</td>\n",
       "      <td>\\n56   DR. 10.7.2019 \\n\\n \\n\\n \\n\\nTuan Yang d...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0      Apakah penyakit yang diderita oleh Sharielda?   \n",
       "1  Siapakah komposer muda yang Chrisye dekati unt...   \n",
       "2  Siapakah yang menfailkan petisyen untuk menunt...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \\nDR. 26.7.2022 103 \\n\\n \\nkemungkinan daripad...      0  test   \n",
       "1  Guruh, dan beliau juga akan berjumpa dengannya...      1  test   \n",
       "2  \\n56   DR. 10.7.2019 \\n\\n \\n\\n \\n\\nTuan Yang d...      0  test   \n",
       "\n",
       "  dataset_source  \n",
       "0   wikipedia-qa  \n",
       "1   wikipedia-qa  \n",
       "2   wikipedia-qa  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-wikipedia-qa.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930392c47a804e39b852578f2301f3bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "batch_size = 10\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    batch = []\n",
    "    with torch.no_grad():\n",
    "        for q, t in zip(test_dataset['query'][n: n + batch_size], test_dataset['text'][n: n + batch_size]):\n",
    "            input_ids = tokenizer.encode_plus(q, t)\n",
    "            input_ids.pop('token_type_ids')\n",
    "            batch.append(input_ids)\n",
    "        padded = tokenizer.pad(batch, return_tensors = 'pt').to('cuda')\n",
    "        scores.extend(reranker_model(**padded).logits.cpu().detach().float().numpy().argmax(axis = 1).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apakah penyakit yang diderita oleh Sharielda?</td>\n",
       "      <td>\\nDR. 26.7.2022 103 \\n\\n \\nkemungkinan daripad...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siapakah komposer muda yang Chrisye dekati unt...</td>\n",
       "      <td>Guruh, dan beliau juga akan berjumpa dengannya...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siapakah yang menfailkan petisyen untuk menunt...</td>\n",
       "      <td>\\n56   DR. 10.7.2019 \\n\\n \\n\\n \\n\\nTuan Yang d...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0      Apakah penyakit yang diderita oleh Sharielda?   \n",
       "1  Siapakah komposer muda yang Chrisye dekati unt...   \n",
       "2  Siapakah yang menfailkan petisyen untuk menunt...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \\nDR. 26.7.2022 103 \\n\\n \\nkemungkinan daripad...      0  test   \n",
       "1  Guruh, dan beliau juga akan berjumpa dengannya...      1  test   \n",
       "2  \\n56   DR. 10.7.2019 \\n\\n \\n\\n \\n\\nTuan Yang d...      0  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0   wikipedia-qa                0  \n",
       "1   wikipedia-qa                1  \n",
       "2   wikipedia-qa                0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenced_df.to_json(\n",
    "    f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl',\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    16452\n",
       "1    16451\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-wikipedia-qa.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "test_dataset = pd.read_json(f\"inferenced_output/{model_used}-inferenced-{f_name}.jsonl\", lines=True, orient='records')\n",
    "scores = test_dataset[\"predicted_label\"]\n",
    "\n",
    "test_dataset[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9980852809774184\n",
      "ROC-AUC: 0.998085287441521\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99830   0.99787   0.99808     16452\n",
      "     class 1    0.99787   0.99830   0.99809     16451\n",
      "\n",
      "    accuracy                        0.99809     32903\n",
      "   macro avg    0.99809   0.99809   0.99809     32903\n",
      "weighted avg    0.99809   0.99809   0.99809     32903\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16417    35]\n",
      " [   28 16423]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
