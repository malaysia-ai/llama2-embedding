{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import torch\n",
    "import flash_attn\n",
    "import pandas as pd\n",
    "from typing import Tuple\n",
    "from tqdm.notebook import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from sklearn.metrics import accuracy_score, classification_report, \\\n",
    "                            roc_auc_score, confusion_matrix\n",
    "\n",
    "model_used = 'bge-v2-gemma'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-reranker-v2-gemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Gemma's activation function should be approximate GeLU and not exact GeLU.\n",
      "Changing the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e389183baf4899803c5ff5e7a3d81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load reranker model\n",
    "reranker_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"BAAI/bge-reranker-v2-gemma\",\n",
    "    use_flash_attention_2 = True,\n",
    "    torch_dtype = torch.bfloat16,\n",
    "    use_cache = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push model to the GPU!\n",
    "_ = reranker_model.cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr 27 06:58:37 2024       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 535.54.03              Driver Version: 535.54.03    CUDA Version: 12.2     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA A100 80GB PCIe          On  | 00000001:00:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P0              62W / 300W |   5284MiB / 81920MiB |      0%      Default |\r\n",
      "|                                         |                      |             Disabled |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "+---------------------------------------------------------------------------------------+\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "yes_loc = tokenizer('Yes', add_special_tokens=False)['input_ids'][0]\n",
    "\n",
    "def get_inputs(\n",
    "    df: pd.DataFrame,\n",
    "    tokenizer,\n",
    "    n: int,\n",
    "    prompt: str = None,\n",
    "    batch_size: int = 10,\n",
    "    max_length: int = 1024\n",
    "):\n",
    "    \"\"\"\n",
    "    This is a utility function which gets the inputs ids for the prompt, separator, and query and passage pair. It was\n",
    "    modified slightly for our use case from the below link.\n",
    "    \n",
    "    Unlike the other Reranker models in our benchmarking exercise, `BAAI/bge-reranker-v2-gemma` is an LLM-based\n",
    "    Reranker. Hence, its inference method is slightly different. More can be found here:\n",
    "    https://github.com/FlagOpen/FlagEmbedding/tree/master/FlagEmbedding/llm_reranker#for-llm-based-reranker-1\n",
    "    \"\"\"\n",
    "    df_ = df.copy()\n",
    "\n",
    "    if prompt is None:\n",
    "        prompt = \"Given a query A and a passage B, determine whether the passage contains an answer to the query by providing a prediction of either 'Yes' or 'No'.\"\n",
    "\n",
    "    sep = \"\\n\"\n",
    "\n",
    "    prompt_inputs = tokenizer(prompt,\n",
    "                              return_tensors=None,\n",
    "                              add_special_tokens=False)['input_ids']\n",
    "\n",
    "    sep_inputs = tokenizer(sep,\n",
    "                           return_tensors=None,\n",
    "                           add_special_tokens=False)['input_ids']\n",
    "    \n",
    "    batch = []\n",
    "    for q, t in zip(df_['query'][n: n + batch_size], df_['text'][n: n + batch_size]):\n",
    "\n",
    "        query_inputs = tokenizer(f'A: {q}',\n",
    "                                 return_tensors=None,\n",
    "                                 add_special_tokens=False,\n",
    "                                 max_length=max_length * 3 // 4,\n",
    "                                 truncation=True)\n",
    "\n",
    "        passage_inputs = tokenizer(f'B: {t}',\n",
    "                                   return_tensors=None,\n",
    "                                   add_special_tokens=False,\n",
    "                                   max_length=max_length,\n",
    "                                   truncation=True)\n",
    "\n",
    "        item = tokenizer.prepare_for_model(\n",
    "            [tokenizer.bos_token_id] + query_inputs['input_ids'],\n",
    "            sep_inputs + passage_inputs['input_ids'],\n",
    "            truncation='only_second',\n",
    "            max_length=max_length,\n",
    "            padding=False,\n",
    "            return_attention_mask=False,\n",
    "            return_token_type_ids=False,\n",
    "            add_special_tokens=False\n",
    "        )\n",
    "\n",
    "        item['input_ids'] = item['input_ids'] + sep_inputs + prompt_inputs\n",
    "        item['attention_mask'] = [1] * len(item['input_ids'])\n",
    "        batch.append(item)\n",
    "\n",
    "    return tokenizer.pad(\n",
    "                batch,\n",
    "                padding=True,\n",
    "                max_length=max_length + len(sep_inputs) + len(prompt_inputs),\n",
    "                pad_to_multiple_of=8,\n",
    "                return_tensors='pt',\n",
    "        ).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_datasets/test-reformatted-common-crawl-qa.jsonl',\n",
       " 'test_datasets/test-reformatted-facebook.jsonl',\n",
       " 'test_datasets/test-reformatted-hansard-qa.jsonl',\n",
       " 'test_datasets/test-reformatted-iium-confession.jsonl',\n",
       " 'test_datasets/test-reformatted-mining-b-cari-com-my.jsonl',\n",
       " 'test_datasets/test-reformatted-mining-summarization.jsonl',\n",
       " 'test_datasets/test-reformatted-news.jsonl',\n",
       " 'test_datasets/test-reformatted-twitter.jsonl',\n",
       " 'test_datasets/test-reformatted-wikipedia-qa.jsonl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list down available files\n",
    "files = sorted(glob.glob('test_datasets/test-reformatted-*.jsonl'))\n",
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Common Crawl QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (20949, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagaimana cara penghantaran dan kos penghantar...</td>\n",
       "      <td>Ladam merupakan barang buatan yang lazimnya di...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apakah jenama bateri kereta yang disediakan ol...</td>\n",
       "      <td>Komik adalah sejenis seni visual yang menggabu...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apakah kawasan liputan untuk servis hantar bat...</td>\n",
       "      <td>untuk memecat Lawton, meninggalkan sekali lagi...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Bagaimana cara penghantaran dan kos penghantar...   \n",
       "1  Apakah jenama bateri kereta yang disediakan ol...   \n",
       "2  Apakah kawasan liputan untuk servis hantar bat...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Ladam merupakan barang buatan yang lazimnya di...      0  test   \n",
       "1  Komik adalah sejenis seni visual yang menggabu...      0  test   \n",
       "2  untuk memecat Lawton, meninggalkan sekali lagi...      0  test   \n",
       "\n",
       "    dataset_source  \n",
       "0  common-crawl-qa  \n",
       "1  common-crawl-qa  \n",
       "2  common-crawl-qa  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-common-crawl-qa.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5271961ff0924321a7216660411e6aad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2095 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2692: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "max_length = 1024\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    with torch.no_grad():\n",
    "        padded = get_inputs(test_dataset, tokenizer, n)\n",
    "        output = reranker_model(**padded, return_dict=True).logits[:, -1, yes_loc] \\\n",
    "                                                           .view(-1, ).cpu().detach() \\\n",
    "                                                           .float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9313093703756743\n",
      "ROC-AUC: 0.9313116283393861\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.97638   0.88401   0.92790     10475\n",
      "     class 1    0.89403   0.97861   0.93441     10474\n",
      "\n",
      "    accuracy                        0.93131     20949\n",
      "   macro avg    0.93520   0.93131   0.93116     20949\n",
      "weighted avg    0.93521   0.93131   0.93116     20949\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9260  1215]\n",
      " [  224 10250]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bagaimana cara penghantaran dan kos penghantar...</td>\n",
       "      <td>Ladam merupakan barang buatan yang lazimnya di...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apakah jenama bateri kereta yang disediakan ol...</td>\n",
       "      <td>Komik adalah sejenis seni visual yang menggabu...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apakah kawasan liputan untuk servis hantar bat...</td>\n",
       "      <td>untuk memecat Lawton, meninggalkan sekali lagi...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>common-crawl-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Bagaimana cara penghantaran dan kos penghantar...   \n",
       "1  Apakah jenama bateri kereta yang disediakan ol...   \n",
       "2  Apakah kawasan liputan untuk servis hantar bat...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Ladam merupakan barang buatan yang lazimnya di...      0  test   \n",
       "1  Komik adalah sejenis seni visual yang menggabu...      0  test   \n",
       "2  untuk memecat Lawton, meninggalkan sekali lagi...      0  test   \n",
       "\n",
       "    dataset_source  predicted_label  \n",
       "0  common-crawl-qa                0  \n",
       "1  common-crawl-qa                0  \n",
       "2  common-crawl-qa                0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inferenced_df.to_json(\n",
    "    f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl',\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0 Facebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sekapur sirih road dah</td>\n",
       "      <td>Abi Ahmad Furqan memang Barisan Nasional dah l...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Menangkan calon pakatan harapan di segi besar</td>\n",
       "      <td>Ismail sabri dan muhiadin</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norlelawati Sukiman amin pra</td>\n",
       "      <td>25k terbaik</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           query  \\\n",
       "0                         Sekapur sirih road dah   \n",
       "1  Menangkan calon pakatan harapan di segi besar   \n",
       "2                   Norlelawati Sukiman amin pra   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Abi Ahmad Furqan memang Barisan Nasional dah l...      0  test   \n",
       "1                          Ismail sabri dan muhiadin      0  test   \n",
       "2                                        25k terbaik      0  test   \n",
       "\n",
       "  dataset_source  \n",
       "0       facebook  \n",
       "1       facebook  \n",
       "2       facebook  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-facebook.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bc5a5dd4fa1478196930755e9011a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2692: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "max_length = 1024\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    with torch.no_grad():\n",
    "        padded = get_inputs(test_dataset, tokenizer, n)\n",
    "        output = reranker_model(**padded, return_dict=True).logits[:, -1, yes_loc] \\\n",
    "                                                           .view(-1, ).cpu().detach() \\\n",
    "                                                           .float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8295555555555556\n",
      "ROC-AUC: 0.840840154767234\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.98744   0.69192   0.81368     24205\n",
      "     class 1    0.73405   0.98976   0.84294     20795\n",
      "\n",
      "    accuracy                        0.82956     45000\n",
      "   macro avg    0.86075   0.84084   0.82831     45000\n",
      "weighted avg    0.87035   0.82956   0.82720     45000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[16748  7457]\n",
      " [  213 20582]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sekapur sirih road dah</td>\n",
       "      <td>Abi Ahmad Furqan memang Barisan Nasional dah l...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Menangkan calon pakatan harapan di segi besar</td>\n",
       "      <td>Ismail sabri dan muhiadin</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Norlelawati Sukiman amin pra</td>\n",
       "      <td>25k terbaik</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           query  \\\n",
       "0                         Sekapur sirih road dah   \n",
       "1  Menangkan calon pakatan harapan di segi besar   \n",
       "2                   Norlelawati Sukiman amin pra   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Abi Ahmad Furqan memang Barisan Nasional dah l...      0  test   \n",
       "1                          Ismail sabri dan muhiadin      0  test   \n",
       "2                                        25k terbaik      0  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0       facebook                1  \n",
       "1       facebook                1  \n",
       "2       facebook                0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-v2-gemma-inferenced-facebook.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.0 Hansard QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (12712, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Siapakah wakil rakyat untuk kawasan Kota Belud?</td>\n",
       "      <td>\\nii DR.07.12.2021 \\n\\n \\n58. YB. Dr. Kelvin Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berapa jumlah unit yang telah dibina oleh PR1M...</td>\n",
       "      <td>from this seller User Review Submit A Review O...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apakah langkah kerajaan yang hendak dikenakan ...</td>\n",
       "      <td>\\n8                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0    Siapakah wakil rakyat untuk kawasan Kota Belud?   \n",
       "1  Berapa jumlah unit yang telah dibina oleh PR1M...   \n",
       "2  Apakah langkah kerajaan yang hendak dikenakan ...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \\nii DR.07.12.2021 \\n\\n \\n58. YB. Dr. Kelvin Y...      1  test   \n",
       "1  from this seller User Review Submit A Review O...      0  test   \n",
       "2  \\n8                                           ...      1  test   \n",
       "\n",
       "  dataset_source  \n",
       "0     hansard-qa  \n",
       "1     hansard-qa  \n",
       "2     hansard-qa  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-hansard-qa.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6a1fa0d5fd467d95c26e3fbb56983c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1272 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2692: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "max_length = 1024\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    with torch.no_grad():\n",
    "        padded = get_inputs(test_dataset, tokenizer, n)\n",
    "        output = reranker_model(**padded, return_dict=True).logits[:, -1, yes_loc] \\\n",
    "                                                           .view(-1, ).cpu().detach() \\\n",
    "                                                           .float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9201541850220264\n",
      "ROC-AUC: 0.9201541850220265\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99981   0.84047   0.91324      6356\n",
      "     class 1    0.86240   0.99984   0.92605      6356\n",
      "\n",
      "    accuracy                        0.92015     12712\n",
      "   macro avg    0.93110   0.92015   0.91964     12712\n",
      "weighted avg    0.93110   0.92015   0.91964     12712\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[5342 1014]\n",
      " [   1 6355]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Siapakah wakil rakyat untuk kawasan Kota Belud?</td>\n",
       "      <td>\\nii DR.07.12.2021 \\n\\n \\n58. YB. Dr. Kelvin Y...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Berapa jumlah unit yang telah dibina oleh PR1M...</td>\n",
       "      <td>from this seller User Review Submit A Review O...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apakah langkah kerajaan yang hendak dikenakan ...</td>\n",
       "      <td>\\n8                                           ...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>hansard-qa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0    Siapakah wakil rakyat untuk kawasan Kota Belud?   \n",
       "1  Berapa jumlah unit yang telah dibina oleh PR1M...   \n",
       "2  Apakah langkah kerajaan yang hendak dikenakan ...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \\nii DR.07.12.2021 \\n\\n \\n58. YB. Dr. Kelvin Y...      1  test   \n",
       "1  from this seller User Review Submit A Review O...      0  test   \n",
       "2  \\n8                                           ...      1  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0     hansard-qa                1  \n",
       "1     hansard-qa                0  \n",
       "2     hansard-qa                1  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-v2-gemma-inferenced-hansard-qa.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.0 IIUM Confession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Means, dia berkurung dalam bilik, tarik muka d...</td>\n",
       "      <td>\"usia 20 an macam ni,memang kita perlukan sora...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saya selalu follow seorang perunding imej feme...</td>\n",
       "      <td>Aku sentiasa ikut seorang consultant image yan...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dan aku juga kasihan akan diriku sendiri. Di r...</td>\n",
       "      <td>And I also pity myself. In that house I was st...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Means, dia berkurung dalam bilik, tarik muka d...   \n",
       "1  Saya selalu follow seorang perunding imej feme...   \n",
       "2  Dan aku juga kasihan akan diriku sendiri. Di r...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \"usia 20 an macam ni,memang kita perlukan sora...      0  test   \n",
       "1  Aku sentiasa ikut seorang consultant image yan...      1  test   \n",
       "2  And I also pity myself. In that house I was st...      1  test   \n",
       "\n",
       "    dataset_source  \n",
       "0  iium-confession  \n",
       "1  iium-confession  \n",
       "2  iium-confession  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-iium-confession.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9e3dc41d884e7d90b848732657a9ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2692: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "max_length = 1024\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    with torch.no_grad():\n",
    "        padded = get_inputs(test_dataset, tokenizer, n)\n",
    "        output = reranker_model(**padded, return_dict=True).logits[:, -1, yes_loc] \\\n",
    "                                                           .view(-1, ).cpu().detach() \\\n",
    "                                                           .float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8511111111111112\n",
      "ROC-AUC: 0.787236353080879\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99978   0.57454   0.72973     15743\n",
      "     class 1    0.81370   0.99993   0.89726     29257\n",
      "\n",
      "    accuracy                        0.85111     45000\n",
      "   macro avg    0.90674   0.78724   0.81349     45000\n",
      "weighted avg    0.87880   0.85111   0.83865     45000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9045  6698]\n",
      " [    2 29255]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Means, dia berkurung dalam bilik, tarik muka d...</td>\n",
       "      <td>\"usia 20 an macam ni,memang kita perlukan sora...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Saya selalu follow seorang perunding imej feme...</td>\n",
       "      <td>Aku sentiasa ikut seorang consultant image yan...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dan aku juga kasihan akan diriku sendiri. Di r...</td>\n",
       "      <td>And I also pity myself. In that house I was st...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>iium-confession</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Means, dia berkurung dalam bilik, tarik muka d...   \n",
       "1  Saya selalu follow seorang perunding imej feme...   \n",
       "2  Dan aku juga kasihan akan diriku sendiri. Di r...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \"usia 20 an macam ni,memang kita perlukan sora...      0  test   \n",
       "1  Aku sentiasa ikut seorang consultant image yan...      1  test   \n",
       "2  And I also pity myself. In that house I was st...      1  test   \n",
       "\n",
       "    dataset_source  predicted_label  \n",
       "0  iium-confession                0  \n",
       "1  iium-confession                1  \n",
       "2  iium-confession                1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-v2-gemma-inferenced-iium-confession.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.0 B Cari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (44910, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello. I am a student. Every time I need to wr...</td>\n",
       "      <td>Hello. Im a student. If I need to write an ess...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>betul ke boleh tapis? dan filter dalam tu mest...</td>\n",
       "      <td>Is it true that it can be filtered? And the fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jangan dia main campak masuk tong sampah bila ...</td>\n",
       "      <td>mmmeeeeowwwwwwwwwwwwwwww</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hello. I am a student. Every time I need to wr...   \n",
       "1  betul ke boleh tapis? dan filter dalam tu mest...   \n",
       "2  Jangan dia main campak masuk tong sampah bila ...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Hello. Im a student. If I need to write an ess...      1  test   \n",
       "1  Is it true that it can be filtered? And the fi...      1  test   \n",
       "2                           mmmeeeeowwwwwwwwwwwwwwww      0  test   \n",
       "\n",
       "         dataset_source  \n",
       "0  mining-b-cari-com-my  \n",
       "1  mining-b-cari-com-my  \n",
       "2  mining-b-cari-com-my  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-mining-b-cari-com-my.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16dd9e4b751f4ea79ddf3e4013aaafae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4491 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2692: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "max_length = 1024\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    with torch.no_grad():\n",
    "        padded = get_inputs(test_dataset, tokenizer, n)\n",
    "        output = reranker_model(**padded, return_dict=True).logits[:, -1, yes_loc] \\\n",
    "                                                           .view(-1, ).cpu().detach() \\\n",
    "                                                           .float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7222444889779559\n",
      "ROC-AUC: 0.6983159218555284\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.98469   0.40195   0.57087     20642\n",
      "     class 1    0.66163   0.99468   0.79467     24268\n",
      "\n",
      "    accuracy                        0.72224     44910\n",
      "   macro avg    0.82316   0.69832   0.68277     44910\n",
      "weighted avg    0.81012   0.72224   0.69181     44910\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 8297 12345]\n",
      " [  129 24139]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello. I am a student. Every time I need to wr...</td>\n",
       "      <td>Hello. Im a student. If I need to write an ess...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>betul ke boleh tapis? dan filter dalam tu mest...</td>\n",
       "      <td>Is it true that it can be filtered? And the fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jangan dia main campak masuk tong sampah bila ...</td>\n",
       "      <td>mmmeeeeowwwwwwwwwwwwwwww</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-b-cari-com-my</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Hello. I am a student. Every time I need to wr...   \n",
       "1  betul ke boleh tapis? dan filter dalam tu mest...   \n",
       "2  Jangan dia main campak masuk tong sampah bila ...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  Hello. Im a student. If I need to write an ess...      1  test   \n",
       "1  Is it true that it can be filtered? And the fi...      1  test   \n",
       "2                           mmmeeeeowwwwwwwwwwwwwwww      0  test   \n",
       "\n",
       "         dataset_source  predicted_label  \n",
       "0  mining-b-cari-com-my                1  \n",
       "1  mining-b-cari-com-my                1  \n",
       "2  mining-b-cari-com-my                0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-v2-gemma-inferenced-mining-b-cari-com-my.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.0 Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (44123, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sektor pertanian dijangka pulih pada 2019 deng...</td>\n",
       "      <td>KUALA LUMPUR: Sektor pertanian dijangka pulih ...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaysia Today, a Malaysian news site, has bee...</td>\n",
       "      <td>Tolong lah gais, aku nasihatkan tolong kunci p...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the Malaysian General Election (GE15), no p...</td>\n",
       "      <td>PUTRAJAYA: Tiada mana-mana parti memperoleh 50...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Sektor pertanian dijangka pulih pada 2019 deng...   \n",
       "1  Malaysia Today, a Malaysian news site, has bee...   \n",
       "2  In the Malaysian General Election (GE15), no p...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  KUALA LUMPUR: Sektor pertanian dijangka pulih ...      1  test   \n",
       "1  Tolong lah gais, aku nasihatkan tolong kunci p...      0  test   \n",
       "2  PUTRAJAYA: Tiada mana-mana parti memperoleh 50...      1  test   \n",
       "\n",
       "         dataset_source  \n",
       "0  mining-summarization  \n",
       "1  mining-summarization  \n",
       "2  mining-summarization  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-mining-summarization.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb9d026dacb400ebc0436bd99c2c0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4413 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2692: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "max_length = 1024\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    with torch.no_grad():\n",
    "        padded = get_inputs(test_dataset, tokenizer, n)\n",
    "        output = reranker_model(**padded, return_dict=True).logits[:, -1, yes_loc] \\\n",
    "                                                           .view(-1, ).cpu().detach() \\\n",
    "                                                           .float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.630963443102237\n",
      "ROC-AUC: 0.7773750467411285\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99975   0.55542   0.71411     36614\n",
      "     class 1    0.31553   0.99933   0.47963      7509\n",
      "\n",
      "    accuracy                        0.63096     44123\n",
      "   macro avg    0.65764   0.77738   0.59687     44123\n",
      "weighted avg    0.88331   0.63096   0.67420     44123\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[20336 16278]\n",
      " [    5  7504]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sektor pertanian dijangka pulih pada 2019 deng...</td>\n",
       "      <td>KUALA LUMPUR: Sektor pertanian dijangka pulih ...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Malaysia Today, a Malaysian news site, has bee...</td>\n",
       "      <td>Tolong lah gais, aku nasihatkan tolong kunci p...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In the Malaysian General Election (GE15), no p...</td>\n",
       "      <td>PUTRAJAYA: Tiada mana-mana parti memperoleh 50...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>mining-summarization</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Sektor pertanian dijangka pulih pada 2019 deng...   \n",
       "1  Malaysia Today, a Malaysian news site, has bee...   \n",
       "2  In the Malaysian General Election (GE15), no p...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  KUALA LUMPUR: Sektor pertanian dijangka pulih ...      1  test   \n",
       "1  Tolong lah gais, aku nasihatkan tolong kunci p...      0  test   \n",
       "2  PUTRAJAYA: Tiada mana-mana parti memperoleh 50...      1  test   \n",
       "\n",
       "         dataset_source  predicted_label  \n",
       "0  mining-summarization                1  \n",
       "1  mining-summarization                1  \n",
       "2  mining-summarization                1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-v2-gemma-inferenced-mining-summarization.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.0 News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bridgerton: sex, gossip and race in Regency Lo...</td>\n",
       "      <td>THE appointment of Najib Razak as chairman of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAS minta putus dengan PKR kerana Selena Gomez</td>\n",
       "      <td>\\n(Focus Malaysia) – Legal practitioner Khairu...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harga MSM dijangka terus meningkat</td>\n",
       "      <td>LONDON, Feb 9 — Lewis Hamilton has signed a o...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Bridgerton: sex, gossip and race in Regency Lo...   \n",
       "1     PAS minta putus dengan PKR kerana Selena Gomez   \n",
       "2                 Harga MSM dijangka terus meningkat   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  THE appointment of Najib Razak as chairman of ...      0  test   \n",
       "1  \\n(Focus Malaysia) – Legal practitioner Khairu...      0  test   \n",
       "2   LONDON, Feb 9 — Lewis Hamilton has signed a o...      0  test   \n",
       "\n",
       "  dataset_source  \n",
       "0           news  \n",
       "1           news  \n",
       "2           news  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-news.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e5e6b808544835a7000c03a18ec8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2692: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "max_length = 1024\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    with torch.no_grad():\n",
    "        padded = get_inputs(test_dataset, tokenizer, n)\n",
    "        output = reranker_model(**padded, return_dict=True).logits[:, -1, yes_loc] \\\n",
    "                                                           .view(-1, ).cpu().detach() \\\n",
    "                                                           .float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8775333333333334\n",
      "ROC-AUC: 0.9240363470498392\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99859   0.85403   0.92067     37446\n",
      "     class 1    0.57873   0.99404   0.73155      7554\n",
      "\n",
      "    accuracy                        0.87753     45000\n",
      "   macro avg    0.78866   0.92404   0.82611     45000\n",
      "weighted avg    0.92811   0.87753   0.88892     45000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[31980  5466]\n",
      " [   45  7509]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bridgerton: sex, gossip and race in Regency Lo...</td>\n",
       "      <td>THE appointment of Najib Razak as chairman of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PAS minta putus dengan PKR kerana Selena Gomez</td>\n",
       "      <td>\\n(Focus Malaysia) – Legal practitioner Khairu...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harga MSM dijangka terus meningkat</td>\n",
       "      <td>LONDON, Feb 9 — Lewis Hamilton has signed a o...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>news</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0  Bridgerton: sex, gossip and race in Regency Lo...   \n",
       "1     PAS minta putus dengan PKR kerana Selena Gomez   \n",
       "2                 Harga MSM dijangka terus meningkat   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  THE appointment of Najib Razak as chairman of ...      0  test   \n",
       "1  \\n(Focus Malaysia) – Legal practitioner Khairu...      0  test   \n",
       "2   LONDON, Feb 9 — Lewis Hamilton has signed a o...      0  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0           news                0  \n",
       "1           news                0  \n",
       "2           news                0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-v2-gemma-inferenced-news.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8.0 Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (45000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@nickgle_ Sugarbun tapi nadai manuk tadi.</td>\n",
       "      <td>@nickgle_ Sugarbun tapi xda ayam td</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semua laki laki sama aja.\\nTapi kalo kamu sama...</td>\n",
       "      <td>@hardliffee Jngan terlalu larut tidurnya yaa</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11:16am PLUS@E1 :  Kerja penyelenggaraan KM 23...</td>\n",
       "      <td>Maintenance work KM 231.0 - KM 233.0 South fro...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0         @nickgle_ Sugarbun tapi nadai manuk tadi.    \n",
       "1  Semua laki laki sama aja.\\nTapi kalo kamu sama...   \n",
       "2  11:16am PLUS@E1 :  Kerja penyelenggaraan KM 23...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0                @nickgle_ Sugarbun tapi xda ayam td      1  test   \n",
       "1       @hardliffee Jngan terlalu larut tidurnya yaa      0  test   \n",
       "2  Maintenance work KM 231.0 - KM 233.0 South fro...      1  test   \n",
       "\n",
       "  dataset_source  \n",
       "0        twitter  \n",
       "1        twitter  \n",
       "2        twitter  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-twitter.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef064612d580484281da0a464165a61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2692: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "max_length = 1024\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    with torch.no_grad():\n",
    "        padded = get_inputs(test_dataset, tokenizer, n)\n",
    "        output = reranker_model(**padded, return_dict=True).logits[:, -1, yes_loc] \\\n",
    "                                                           .view(-1, ).cpu().detach() \\\n",
    "                                                           .float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8801333333333333\n",
      "ROC-AUC: 0.8588266154242548\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99283   0.72146   0.83567     19010\n",
      "     class 1    0.83021   0.99619   0.90566     25990\n",
      "\n",
      "    accuracy                        0.88013     45000\n",
      "   macro avg    0.91152   0.85883   0.87066     45000\n",
      "weighted avg    0.89891   0.88013   0.87609     45000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[13715  5295]\n",
      " [   99 25891]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@nickgle_ Sugarbun tapi nadai manuk tadi.</td>\n",
       "      <td>@nickgle_ Sugarbun tapi xda ayam td</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Semua laki laki sama aja.\\nTapi kalo kamu sama...</td>\n",
       "      <td>@hardliffee Jngan terlalu larut tidurnya yaa</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11:16am PLUS@E1 :  Kerja penyelenggaraan KM 23...</td>\n",
       "      <td>Maintenance work KM 231.0 - KM 233.0 South fro...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>twitter</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0         @nickgle_ Sugarbun tapi nadai manuk tadi.    \n",
       "1  Semua laki laki sama aja.\\nTapi kalo kamu sama...   \n",
       "2  11:16am PLUS@E1 :  Kerja penyelenggaraan KM 23...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0                @nickgle_ Sugarbun tapi xda ayam td      1  test   \n",
       "1       @hardliffee Jngan terlalu larut tidurnya yaa      0  test   \n",
       "2  Maintenance work KM 231.0 - KM 233.0 South fro...      1  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0        twitter                1  \n",
       "1        twitter                1  \n",
       "2        twitter                1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-v2-gemma-inferenced-twitter.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9.0 Wikipedia QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (32903, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apakah penyakit yang diderita oleh Sharielda?</td>\n",
       "      <td>\\nDR. 26.7.2022 103 \\n\\n \\nkemungkinan daripad...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siapakah komposer muda yang Chrisye dekati unt...</td>\n",
       "      <td>Guruh, dan beliau juga akan berjumpa dengannya...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siapakah yang menfailkan petisyen untuk menunt...</td>\n",
       "      <td>\\n56   DR. 10.7.2019 \\n\\n \\n\\n \\n\\nTuan Yang d...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0      Apakah penyakit yang diderita oleh Sharielda?   \n",
       "1  Siapakah komposer muda yang Chrisye dekati unt...   \n",
       "2  Siapakah yang menfailkan petisyen untuk menunt...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \\nDR. 26.7.2022 103 \\n\\n \\nkemungkinan daripad...      0  test   \n",
       "1  Guruh, dan beliau juga akan berjumpa dengannya...      1  test   \n",
       "2  \\n56   DR. 10.7.2019 \\n\\n \\n\\n \\n\\nTuan Yang d...      0  test   \n",
       "\n",
       "  dataset_source  \n",
       "0   wikipedia-qa  \n",
       "1   wikipedia-qa  \n",
       "2   wikipedia-qa  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = \"test_datasets/test-reformatted-wikipedia-qa.jsonl\"\n",
    "f_name = f.split('reformatted-')[-1].split('.')[0]\n",
    "\n",
    "test_dataset = pd.read_json(f, lines=True)\n",
    "test_dataset['dataset_source'] = f_name\n",
    "\n",
    "print('Shape:', test_dataset.shape)\n",
    "test_dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a9407ad26943f2861302784438043e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2692: UserWarning: `max_length` is ignored when `padding`=`True` and there is no truncation strategy. To pad to max length, use `padding='max_length'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# initialize a list to store all the scores\n",
    "scores = []\n",
    "max_length = 1024\n",
    "\n",
    "for n in tqdm(range(0, len(test_dataset), batch_size)):\n",
    "    with torch.no_grad():\n",
    "        padded = get_inputs(test_dataset, tokenizer, n)\n",
    "        output = reranker_model(**padded, return_dict=True).logits[:, -1, yes_loc] \\\n",
    "                                                           .view(-1, ).cpu().detach() \\\n",
    "                                                           .float().numpy().tolist()\n",
    "        scores.extend([1 if score > 0 else 0 for score in output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7811749688478254\n",
      "ROC-AUC: 0.7811815915451412\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0    0.99838   0.56327   0.72021     16452\n",
      "     class 1    0.69582   0.99909   0.82032     16451\n",
      "\n",
      "    accuracy                        0.78117     32903\n",
      "   macro avg    0.84710   0.78118   0.77027     32903\n",
      "weighted avg    0.84711   0.78117   0.77027     32903\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 9267  7185]\n",
      " [   15 16436]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate predictions (macro)\n",
    "true_labels = test_dataset[\"label\"]\n",
    "accuracy = accuracy_score(true_labels, scores)\n",
    "roc_auc = roc_auc_score(true_labels, scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"ROC-AUC:\", roc_auc)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    true_labels,\n",
    "    scores,\n",
    "    target_names=[\"class 0\", \"class 1\"],\n",
    "    digits=5\n",
    "))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(true_labels, scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>dataset_source</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apakah penyakit yang diderita oleh Sharielda?</td>\n",
       "      <td>\\nDR. 26.7.2022 103 \\n\\n \\nkemungkinan daripad...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Siapakah komposer muda yang Chrisye dekati unt...</td>\n",
       "      <td>Guruh, dan beliau juga akan berjumpa dengannya...</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Siapakah yang menfailkan petisyen untuk menunt...</td>\n",
       "      <td>\\n56   DR. 10.7.2019 \\n\\n \\n\\n \\n\\nTuan Yang d...</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>wikipedia-qa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               query  \\\n",
       "0      Apakah penyakit yang diderita oleh Sharielda?   \n",
       "1  Siapakah komposer muda yang Chrisye dekati unt...   \n",
       "2  Siapakah yang menfailkan petisyen untuk menunt...   \n",
       "\n",
       "                                                text  label split  \\\n",
       "0  \\nDR. 26.7.2022 103 \\n\\n \\nkemungkinan daripad...      0  test   \n",
       "1  Guruh, dan beliau juga akan berjumpa dengannya...      1  test   \n",
       "2  \\n56   DR. 10.7.2019 \\n\\n \\n\\n \\n\\nTuan Yang d...      0  test   \n",
       "\n",
       "  dataset_source  predicted_label  \n",
       "0   wikipedia-qa                1  \n",
       "1   wikipedia-qa                1  \n",
       "2   wikipedia-qa                1  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and export inferenced dataframe\n",
    "inferenced_df = pd.concat([test_dataset, pd.DataFrame(scores, columns=['predicted_label'])], axis=1)\n",
    "inferenced_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferenced_output/bge-v2-gemma-inferenced-wikipedia-qa.jsonl\n"
     ]
    }
   ],
   "source": [
    "file_output = f'inferenced_output/{model_used}-inferenced-{f_name}.jsonl'\n",
    "print(file_output)\n",
    "\n",
    "inferenced_df.to_json(\n",
    "    file_output,\n",
    "    orient='records',\n",
    "    lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
